{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Selc6oSpUtaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n"
      ],
      "metadata": {
        "id": "kBNXgL_EyOyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODEL KLASYCZNY ML\n"
      ],
      "metadata": {
        "id": "JkdHkbq5yR32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import load_npz\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import joblib\n",
        "\n",
        "X_train = load_npz('data/processed/X_train_tfidf.npz')\n",
        "X_test  = load_npz('data/processed/X_test_tfidf.npz')\n",
        "\n",
        "y_train = np.load('data/processed/y_train.npy')\n",
        "y_test  = np.load('data/processed/y_test.npy')\n",
        "\n",
        "X_train.shape, X_test.shape\n"
      ],
      "metadata": {
        "id": "wguzAq5wyTDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ml_model = LogisticRegression(\n",
        "    max_iter=1000,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "ml_model.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "NNO-5Np1yc2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_ml = ml_model.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_ml))\n",
        "print(classification_report(y_test, y_pred_ml))\n"
      ],
      "metadata": {
        "id": "PU_SmOl2yfc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('models', exist_ok=True)\n",
        "joblib.dump(ml_model, 'models/logistic_regression.pkl')\n"
      ],
      "metadata": {
        "id": "bYQEHI65yjzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SIEÄ† NEURONOWA OD ZERA"
      ],
      "metadata": {
        "id": "4pgqRLDbysft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n"
      ],
      "metadata": {
        "id": "CT91AgkzytJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_dense = torch.tensor(X_train.toarray(), dtype=torch.float32)\n",
        "X_test_dense  = torch.tensor(X_test.toarray(), dtype=torch.float32)\n",
        "\n",
        "y_train_t = torch.tensor(y_train, dtype=torch.float32)\n",
        "y_test_t  = torch.tensor(y_test, dtype=torch.float32)\n",
        "\n",
        "train_ds = TensorDataset(X_train_dense, y_train_t)\n",
        "test_ds  = TensorDataset(X_test_dense, y_test_t)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n"
      ],
      "metadata": {
        "id": "bVIW0n5DywEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n"
      ],
      "metadata": {
        "id": "PvbISSqoy0fD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "model_nn = SimpleNN(X_train.shape[1]).to(device)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model_nn.parameters(), lr=0.001)\n",
        "\n",
        "epochs = 5\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model_nn.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for Xb, yb in train_loader:\n",
        "        Xb, yb = Xb.to(device), yb.to(device).unsqueeze(1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        preds = model_nn(Xb)\n",
        "        loss = criterion(preds, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs} - Loss: {total_loss:.4f}\")\n"
      ],
      "metadata": {
        "id": "xVStKjQ4y2rx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_nn.eval()\n",
        "with torch.no_grad():\n",
        "    preds = model_nn(X_test_dense.to(device)).cpu().numpy()\n",
        "    preds = (preds > 0.5).astype(int)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, preds))\n",
        "print(classification_report(y_test, preds))\n"
      ],
      "metadata": {
        "id": "yv7ABnexy4z9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model_nn.state_dict(), 'models/nn_from_scratch.pt')\n"
      ],
      "metadata": {
        "id": "Uz9T3teWy6SO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRANSFORMER (FINE-TUNING)"
      ],
      "metadata": {
        "id": "OOykiRH-0OZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers datasets accelerate\n"
      ],
      "metadata": {
        "id": "E8QccYVB0PTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "from datasets import Dataset\n"
      ],
      "metadata": {
        "id": "lqXtMqkP0RSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('data/processed/train_transformer.csv')\n",
        "test_df  = pd.read_csv('data/processed/test_transformer.csv')\n",
        "\n",
        "train_df = train_df.sample(3000, random_state=42)\n",
        "test_df  = test_df.sample(500, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "train_df.head()\n"
      ],
      "metadata": {
        "id": "H1qkmCdV0UBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def tokenize(batch):\n",
        "    return tokenizer(\n",
        "        batch['clean_text'],\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        max_length=128\n",
        "    )\n",
        "\n",
        "train_ds = Dataset.from_pandas(train_df)\n",
        "test_ds  = Dataset.from_pandas(test_df)\n",
        "\n",
        "train_ds = train_ds.map(tokenize, batched=True)\n",
        "test_ds  = test_ds.map(tokenize, batched=True)\n",
        "\n",
        "train_ds = train_ds.rename_column(\"label\", \"labels\")\n",
        "test_ds  = test_ds.rename_column(\"label\", \"labels\")\n",
        "\n",
        "train_ds.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "test_ds.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n"
      ],
      "metadata": {
        "id": "O9kJ3JOe0a_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=2\n",
        ")\n"
      ],
      "metadata": {
        "id": "9R26LRk_0dTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"models/transformer\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=1,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"results/logs\",\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=transformer_model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=test_ds,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "id": "ck7uoPrO0goM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()\n"
      ],
      "metadata": {
        "id": "Ah0hdJK10jJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model(\"models/transformer\")\n",
        "tokenizer.save_pretrained(\"models/transformer\")\n"
      ],
      "metadata": {
        "id": "n8SISzv20lIb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
